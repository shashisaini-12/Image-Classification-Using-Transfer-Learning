{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aELKrMRYFzr_vVRYRTZ77RZpBkI0-ejQ",
      "authorship_tag": "ABX9TyMKKlmUyo7iv60dVbnbrPu/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashisaini-12/Image-Classification-Using-Transfer-Learning/blob/main/Transfer_Learning_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sn"
      ],
      "metadata": {
        "id": "1f7pSQjOlDuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CST3ujn7-Hv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "673a0d12-d3bb-4dc2-a5e3-1dc2fbc1ae84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6231 images belonging to 24 classes.\n",
            "Found 3110 images belonging to 24 classes.\n",
            "Found 3114 images belonging to 24 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras import Model as model\n",
        "import tensorflow as tf\n",
        "device = '/device:GPU:0'\n",
        "device\n",
        "  #Zipped dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/DataSets/fruit_image.zip\"\n",
        "#!unzip '/content/drive/MyDrive/DataSets/fruit_image.zip' -d '/content/drive/MyDrive/DataSets'\n",
        "afer_extraction_dataset = \"/content/drive/MyDrive/DataSets/fruits-360-original-size/fruits-360-original-size\"\n",
        "labeling_job = ImageDataGenerator(rescale = 1.0/255)\n",
        "train_label = labeling_job.flow_from_directory(\"/content/drive/MyDrive/DataSets/fruits-360-original-size/fruits-360-original-size/Training\",\n",
        "                                               target_size=(260, 260), batch_size=32)\n",
        "test_label = labeling_job.flow_from_directory(\"/content/drive/MyDrive/DataSets/fruits-360-original-size/fruits-360-original-size/Test\",\n",
        "                                              target_size=(260, 260), batch_size=32)\n",
        "validation_label = labeling_job.flow_from_directory(\"/content/drive/MyDrive/DataSets/fruits-360-original-size/fruits-360-original-size/Validation\",\n",
        "                                                    target_size=(260, 260), batch_size=32)\n",
        "Model = Sequential()\n",
        "\n",
        "Model.add(Conv2D(32, (3, 3), input_shape=(260, 260, 3)))\n",
        "Model.add(MaxPool2D((3, 3)))\n",
        "\n",
        "Model.add(Conv2D(64, (3, 3)))\n",
        "Model.add(MaxPool2D(3, 3))\n",
        "\n",
        "Model.add(Conv2D(128, (3, 3)))\n",
        "Model.add(MaxPool2D((3, 3)))\n",
        "\n",
        "Model.add(Conv2D(256, (3, 3)))\n",
        "Model.add(MaxPool2D((3, 3)))\n",
        "\n",
        "Model.add(MaxPool2D((2, 2)))\n",
        "Model.add(Flatten())\n",
        "\n",
        "Model.add(Dense(train_label.num_classes, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model.compile(optimizer = 'adam', loss='CategoricalCrossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BSnAnKpmE1r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model.fit(train_label, epochs =1, validation_data=validation_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k3PeeNTE1ue",
        "outputId": "5eeea42b-428f-4f2b-c728-52933b223643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - ETA: 0s - loss: 0.8136 - accuracy: 0.7551 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_path = \"/content/drive/MyDrive/DataSets/fruits-360-original-size/fruits-360-original-size/Test\""
      ],
      "metadata": {
        "id": "Pjjz-xWtksUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir(testing_path):\n",
        "  for j in os.listdir(os.path.join(testing_path, i)):\n",
        "    my_img = load_img(os.path.join(testing_path, i, j))\n",
        "    x = np.expand_dims(my_img.resize((260, 260)), axis=0)\n",
        "    y = Model.predict(x)\n",
        "    y_class = y.argmax()\n",
        "    plt.imshow(my_img)\n",
        "    print('correct class for image {}'.format(i))\n",
        "    print('predicted class is {}'.format(list(train_label.class_indices.keys())[y_class]))\n"
      ],
      "metadata": {
        "id": "K8k6ImEiksXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "y_actual = []\n",
        "test_label.reset()\n",
        "\n",
        "for i in range(len(test_label.filenames)):\n",
        "  x, y = test_label.next()\n",
        "  y_pred.append(Model.predict(x).argmax())\n",
        "  y_actual.append(y.argmax())"
      ],
      "metadata": {
        "id": "mnV9m-bZksaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual[:5]"
      ],
      "metadata": {
        "id": "brG3GDqJhj8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_list = [list(train_label.class_indices.keys())[i] for i in y_pred]\n",
        "actual_list = [list(train_label.class_indices.keys())[i] for i in y_actual]"
      ],
      "metadata": {
        "id": "SyuEXloWNKPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame(np.vstack([pred_list, actual_list]).T, columns=['Predicted_class', 'Actual_class'])"
      ],
      "metadata": {
        "id": "r0CHunP8NKVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = pd.crosstab(output_df['Actual_class'], output_df['Predicted_class'], rownames=['Actual'], colnames=['Predicted'])"
      ],
      "metadata": {
        "id": "4Zc_VdKUNKZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sn.heatmap(confusion_matrix, cmap='copper', annot=True, fmt='d')\n",
        "plt.show"
      ],
      "metadata": {
        "id": "Uf7iIAJQN9n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = Model.to_json()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/DataSets/fruits-360-original-size/fruits-360-original-size/saved_model.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "# Serialize weights to HDF5\n",
        "Model.save_weights(\"/content/drive/MyDrive/DataSets/fruits-360-original-size/fruits-360-original-size/saved_model.h5\")\n",
        "print(\"saved model to disk\")"
      ],
      "metadata": {
        "id": "ZtIl8Vy6NKpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hlyHTP1INKzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IjwoI0ZRNK5B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}